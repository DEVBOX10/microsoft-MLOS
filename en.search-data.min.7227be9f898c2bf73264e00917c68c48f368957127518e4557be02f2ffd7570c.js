'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/MLOS/CODE_OF_CONDUCT/','title':"C O D E O F C O N D U C T",'section':"",'content':"Microsoft Open Source Code of Conduct This project has adopted the Microsoft Open Source Code of Conduct.\nResources:\n Microsoft Open Source Code of Conduct Microsoft Code of Conduct FAQ Contact opencode@microsoft.com with questions or concerns  "});index.add({'id':1,'href':'/MLOS/CONTRIBUTING/','title':"C O N T R I B U T I N G",'section':"",'content':"Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.\nThis project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.\nFor more details on the specifics of contributing please see documentation/04-Contributing/.\n"});index.add({'id':2,'href':'/MLOS/documentation/01-Prerequisites/','title':"01 Prerequisites",'section':"Documentation",'content':"Prerequisites for building and using MLOS These are one-time setup instructions that should be executed prior to following the build instructions in 02-Build/\nContents  Requirements Clone the repository Install build tools  Linux Windows   Install Python Dependencies  Linux Windows   Install Docker  Linux Windows     Note: Most Windows shell commands here expect powershell (or pwsh).\n Requirements MLOS currently only supports 64-bit Intel/AMD platforms, though ARM64 support is under development.\nIt supports Windows and Linux environments.\n  Windows\n Portions of MLOS require Docker, which requires a Linux VM. So support for one of the following is required:\n  WSL2 (e.g. Windows 10 build \u0026gt;= 2004, including Pro, Enterprise, and Home), or Hyper-V support (only Windows 10 Pro/Enterprise, not Home)   Note: WSL2 is advised for ease of setup, integrations with Docker, and more flexible resource utilizations benefits.\n   Linux\n Ubuntu 18.04 (bionic), 20.04 (focal) Debian 9 (stretch), 10 (buster)    Clone the repository Cross platform\ngit clone https://github.com/microsoft/MLOS.git\r See https://git-scm.com/book/en/v2/Getting-Started-Installing for help installing git.\n Install build tools Linux build tools TODO\nWindows build tools There are several build tools install paths to choose from on Windows.\n Note: For most of these commands we first need a powershell with Administrator privileges:\n   Start a powershell environment with Administrator privileges:\npowershell -NoProfile -Command \u0026#34;Start-Process powershell -Verb RunAs\u0026#34;\r If you find that when you start a new shell environment it can\u0026rsquo;t find some of the tools installed later on, the new PATH environment variable might not be updated. Try to restart your machine.\n   Allow local powershell scripts to be executed:\nSet-ExecutionPolicy RemoteSigned -Scope CurrentUser -Force\r This is necessary for our build environment initialization script scripts/init.windows.ps1 as well.\n   Using a local script   Launch the script we provide in the MLOS repo to install/update Visual Studio 2019 Community Edition with the necessary components:\n.\\scripts\\install-vs2019.ps1\rWaiting for installer process vs_community to end ...\rWaiting for installer process vs_community to end ...\r...\rDone\r Note: This will install the free Community edition by default. Use the -Sku option if you prefer to install the Enterprise version instead.\n   Using Chocolatey Chocolatey is a package manager for Windows to help support scripted and reproducable installation of tools.\n Install chocolatey:\nSet-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString(\u0026#39;https://chocolatey.org/install.ps1\u0026#39;))\rGetting latest version of the Chocolatey package for download.\r...\rChocolatey (choco.exe) is now ready.\rYou can call choco from anywhere, command line or powershell by typing choco.\rRun choco /? for a list of functions.\rYou may need to shut down and restart powershell and/or consoles\rfirst prior to using choco.\r...\rSee Also: https://chocolatey.org/install\n  Install build tools:\nchoco install -y git\rchoco install -y dotnetcore-runtime.install --params=\u0026#34;Skip32Bit\u0026#34;\rchoco install -y dotnetcore dotnetcore-sdk\rchoco install -y visualstudio2019buildtools visualstudio2019-workload-netcorebuildtools visualstudio2019-workload-vctools\r  Install an editor (optional)\nchoco install -y vscode\rchoco install -y vscode-cpptools vscode-csharp vscode-cake\ror\nchoco install -y visualstudio2019community\r  Manually Download and install Visual Studio 2019 (free) Community Edition:\nhttps://visualstudio.microsoft.com/vs/community/\nBe sure to include support for .Net Core, C++, CMake\nInstall Python Dependencies Linux Python Install   Install Python 3.x\nsudo apt -y install python3 python3-pip\r  Install MLOS Python dependencies:\n# Also add some dependencies needed by some of the pip modules\rsudo apt -y install build-essential libfreetype-dev unixodbc-dev\rpip3 install -r source/Mlos.Python/requirements.txt\r  Windows Python Install Using Chocolatey  See above for instructions on installing Chocolatey.\n  Install Python\nchoco install -y python --version=3.7.8\r  Install MLOS Python dependencies:\npip install -r source\\Mlos.Python\\requirements.txt\r  Install Docker Linux Docker Install TODO\nWindows Docker Install As mentioned above, Docker on Windows first requires a Linux VM.\n As such, if your Windows development environment is itself a VM, you\u0026rsquo;ll need one that supports nested virtualization.\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/acu\n   The easiest route is through WSL2:\n  Enable WSL2 on Windows 10 build 2004 or later:\ndism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart\rdism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart\rInvoke-WebRequest -Uri https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi -OutFile wsl_update_x64.msi -UseBasicParsing\rInvoke-Item wsl_update_x64.msi\r Note: You may need to restart at this point.\n wsl --set-default-version 2\r  Install a Linux distro for WSL2 (e.g. Ubuntu 20.04):\nInvoke-WebRequest -Uri https://aka.ms/wslubuntu2004 -OutFile Ubuntu-20.04.appx -UseBasicParsing\rAdd-AppxPackage ./Ubuntu-20.04.appx\r Finish the installation by launching the \u0026ldquo;Ubuntu 20.04\u0026rdquo; distribution from the Start menu to setup your Linux account in the WSL distribution.\n   Install Docker\n  Chocolatey\nchoco install docker-desktop docker-cli\r  Manually\nhttps://docs.docker.com/docker-for-windows/install/\n  Configure Docker Desktop to use WSL2\n  At this point docker commands should work naturally from any shell environment and proxied through to the WSL2 Linux distribution configured in Docker Desktop.\n  Alternatively, you can enable Hyper-V and use docker-machine to create a VM suitable for running Docker containers:\n Note: This isn\u0026rsquo;t supported on Windows Home edition.\n   Enable Hyper-V\nEnable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All\r  Install docker-machine:\n  Manually:\nhttps://docs.docker.com/machine/install-machine/\n  Or, via Chocolatey:\nchoco install docker-machine\r    Build a VM for running Docker containers:\ndocker-machine create --driver hyperv --hyperv-virtual-switch \u0026#34;NameOfYourDockerVSwitch\u0026#34; docker-dev-vm\r  Invoke a shell environment to use it:\ndocker-machine env --shell powershell docker-dev-vm | Invoke-Expression\rFrom within this shell environment, docker cli commands should be proxied through to your docker-dev-vm prepared by docker-machine.\n    "});index.add({'id':3,'href':'/MLOS/documentation/02-Build/','title':"02 Build",'section':"Documentation",'content':"Build Instructions for MLOS Prerequisites See 01-Prerequisites/ for initial build tools setup instructions.\nLinux TODO\nWindows CLI Visual Studio build tools need to be added to the shell environment.\n Note: Visual Studio build tools are available free.\nPlease see the initial setup instructions linked above for details.\n   Setup the powershell environment to find the Visual Studio build tools.\n.\\scripts\\init.windows.ps1\r Note: you can also execute .\\scripts\\init.windows.cmd if you prefer a cmd environment.\n   Use msbuild to build the project file in the current directory.\n e.g. when run from the root of the MLOS repo this will recursively build all the projects and run the tests.\n msbuild /m /r\rSome additional build flags to help provide additional control over the process:\n /m runs a multi-process parallel build process /r is required on first build and git pull to restore any nuget packages required \\ /fl will optionally produce a msbuild.log file /p:RunUnitTest=false will temporarily skip running unit tests /p:StyleCopEnabled=false will temporarily skip C# style checks /p:UncrustifyEnabled=false will temporarily skip C++ style checks /p:BuildProjectReferences=false will temporarily only build the current project file, and skip rebuilding its dependencies (note: this option doesn\u0026rsquo;t work when building .sln files)    Visual Studio  Note: Visual Studio 2019 Community Edition is available free.\nPlease see the initial setup instructions linked above for details.\n Opening a *.sln file in the source/ directory with Visual Studio 2019 should allow you to build inside the IDE.\n  Setup the shell environment to find the devenv script provided by Visual Studio.\n.\\scripts\\init.windows.ps1\r Note: you can also execute .\\scripts\\init.windows.cmd if you prefer a cmd environment.\n   Launch Visual Studio for a given solution:\ndevenv MLOS.NetCore.sln\rAlternatively, you can launch devenv for a project and manually add its dependencies to the solution that Visual Studio creates. For instance:\ndevenv MLOS.Core.vcxproj\r  "});index.add({'id':4,'href':'/MLOS/documentation/03-ExampleUsage/','title':"03 Example Usage",'section':"Documentation",'content':"Examples of using MLOS to optimize a system TODO\n"});index.add({'id':5,'href':'/MLOS/documentation/04-Contributing/','title':"04 Contributing",'section':"Documentation",'content':"Contributing to MLOS TODO: Write up some instructions for contributing to MLOS codebase itself.\n"});index.add({'id':6,'href':'/MLOS/documentation/05-Test/','title':"05 Test",'section':"Documentation",'content':"Test Instructions for MLOS TODO: document how to run unit tests for\n C++ C#  Python First, ensure that the necessary Python modules are installed. See 01-Prerequisites/ for details.\nLinux scripts/run-python-tests.sh Windows scripts\\run-python-tests.cmd "});index.add({'id':7,'href':'/MLOS/documentation/06-Debug/','title':"06 Debug",'section':"Documentation",'content':"TODO\n"});index.add({'id':8,'href':'/MLOS/documentation/','title':"Documentation",'section':"",'content':"MLOS Documentation This directory contains project wide documentation for things like coding standards, overall architecture descriptions, build instructions, etc.\nIndividual components may also include their own more detailed documentation within their subdirectories.\n Note: Some documentation uses Mermaid for diagrams in addition to Markdown.\nYou can install Markdown Preview Enhanced for Atom or Visual Code to help render it more easily.\n Getting Started Here\u0026rsquo;s a brief summary of some documentation suggestions to help get started:\n See 01-Prerequisites/ for initial environment setup instructions. See 02-Build/ for basic build instructions. See 03-ExampleUsage/ for some usage examples for applying MLOS to some code/system. See 04-Contributing/ for notes on making changes to MLOS itself. See 05-Test/ for notes on testing those changes. See 06-Debug/ for notes on debugging those changes.  Overview Here\u0026rsquo;s some documentation references describing the MLOS architecture:\n MlosArchitecture/ Glossary/ DEEM 2020 Paper  Here\u0026rsquo;s a document describing the layout of the repository:\n RepoOrganization/  "});index.add({'id':9,'href':'/MLOS/documentation/CodingStandard/','title':"Coding Standard",'section':"Documentation",'content':"MLOS Coding Standards MLOS uses and supports multiple languages. Here we document the coding styles and standards we attempt to adhere to and the tools we use to achieve that.\nC++ For C++ we mostly try to follow the Google C++ style guidelines, with a few modifications.\nCurrently we rely on uncrustify to help enforce these rules (plus a little bit of human review).\nSee build/uncrustify/README/ for additional information.\nThough we attempt to make it somewhat readable, we exclude code generated by MLOS from these strict style checks.\nuncrustify is invoked as a part of the build process (see 02-Build/ for details on temporarily disabling it locally).\nC# We use StyleCopAnalyzers to mostly follow the standard recommended C# style guidelines, with a few exceptions listed in build/MLOS.NetCore.ruleset.\nThough we attempt to make it somewhat readable, we exclude code generated by MLOS from these strict style checks using an \u0026lt;auto-generated /\u0026gt; tag file header.\nStyleCop is invoked as a part of the build process (see 02-Build/ for details on temporarily disabling it locally).\nPython We use pylint for Python code to mostly follow PEP 8 guidelines. Its configuration can be found at source/.pylintrc.\nTo run it locally, issues the following commands:\n  One time instal of the pylint tool:\npip install pylint\r  Followed by:\n  Linux:\nscripts/run-python-checks.sh\r  Windows:\nscripts\\run-python-checks.cmd\r    We also use licenseheaders to add ensure license headers are added to .py files.\nTo run it locally, issues the following commands:\n  One time install of the licenseheaders tool:\npip install licenseheaders\r  Followed by:\n  Linux:\nscripts/update-python-license-headers.sh\r  Windows:\nscripts\\update-python-license-headers.cmd\r     Note: Currently this has issues with conflicting cross-platform line-ending styles.\nUse git diff --ignore-cr-at-eol to identify the differences.\n "});index.add({'id':10,'href':'/MLOS/documentation/Glossary/','title':"Glossary",'section':"Documentation",'content':"MLOS Terms Glossary TODO\n"});index.add({'id':11,'href':'/MLOS/documentation/MlosArchitecture/','title':"Mlos Architecture",'section':"Documentation",'content':"MLOS Architecture This document provides a brief overview of the MLOS architecture for supporting Machine Learning Optimized Systems.\n MLOS Architecture  High Level Description  Principles Workflows   Architecture Diagram  Main Components Shared Memory Regions Target process  Mlos.Core Shared Channel   Mlos.Agent  Mlos.NetCore Settings Registry Assemblies Grpc Server Experiment Management     Implementation Details    High Level Description At a high level, MLOS provides infrastructure to support instance-specific tuning systems software (e.g. written in C++) in a trackable and reproducible way.\nMLOS does this by focusing on optimizing tunables that exist in code.\nTunables can take several forms:\n Build time  e.g. inlined constants controlling buffer size or hash function, choice of concrete ADT implementation, etc.   Startup  e.g. configurations that can only be changed with a process restart   Runtime  e.g. dynamic settings that can changed between instantiations, queries, or other events. Some of these may be known at compile-time, while others may only be known at runtime for a specific instance (e.g. number of tables in a database schema).    To optimize these tunables, the system needs to be observable. In other words, it needs to provide additional data (e.g. workload, telemetry, metrics, etc.) about the its operation. When combined additional information obtained from the system executing the process (e.g. OS/HW metrics), we call this combined set of information the context.\nPrinciples   Separation\nTo support lightweight observable components with minimal impact on the target system\u0026rsquo;s performance, we separate the data aggregation and optimization steps to a (local) external agent process. It communicates with the target system using shared memory channels for low latency.\n  Segmentation\nTo support faster iteration, we allow focusing build-time constant tuning to specific components of the target system using micro benchmarks.\n  Workflows MLOS workflows take roughly two basic forms:\n  Build-time optimization\nMicrobenchmarks develepers write for smart components can be used to explore component tunable parameter values either interactively or in the background (e.g. during continuous integration pipelines).\nThe data collected from those \u0026ldquo;experiments\u0026rdquo; can be captured and explored in Notebook experiences that can then be checked back in with the resulting code change to help support reproducible tests to validate these parameters in the future.\nSince these tunables may affect many instances, optimization goals here may focus on robustness in addition to performance or some other metric.\n  Runtime optimization\nSmart components can be hooked up to receive suggestions from the external agent during runtime for online instance specific optimizations as well.\n  Architecture Diagram Main components   Target process\nThis is the MLOS enabled system to tune (e.g. an end-to-end system like SqlServer or Smart micro benchmarks for a component, etc.). The process contains tunable \u0026ldquo;Smart\u0026rdquo; components that are made observable by the Mlos.Agent by exporting telemetry/metrics over Shared memory channels and are optimized using Mlos.Optimizer.Service suggestions.\n  Mlos.Agent\nThe primary responsibility of the Mlos.Agent is to observe the target process and manage the \u0026ldquo;experiments\u0026rdquo;. The experiments define the aggregates from the telemetry stream and exchange it with Mlos.Optimizer.Service.\n  Mlos.Client\nThe Mlos.Client is a utility application that allows us to query the state of shared components and create new experiments.\n  Shared memory\nShared memory regions are used to exchange messages and share the configuration objects between the Target process and the Mlos.Agent.\n  Mlos.Optimizer.Service\nMlos.Optimizer.Service is a Docker instance containing the Mlos.Optimizer and an RDBMS instance (e.g. SqlServer) for storing experiment data, optimizer models, etc.\nTo exchange the messages between Mlos.Agent experiments and Mlos.Optimizers, the database is currently used as a transport channel.\n  Shared Memory Regions   Global Shared Memory\nThe primary shared memory entry point. It used to bootstrap and contains metadata about all other memory regions. It also includes shared channel synchronization objects.\n  Config Shared Memory\nWe store all components\u0026rsquo; configuration in the config shared memory region. Configuration objects are accessible from the Target process and from Mlos.Agent.\n  Control/Telemetry Channel Shared Memory\nMemory region used (exclusively, no header) to exchange messages from the Target process to Mlos.Agent.\n  Feedback Channel Shared Memory\nA memory region used (exclusively, no header) to exchange messages from Mlos.Agent to Target process.\n  Some memory regions contain a header block that helps with their identification. The exceptions are shared channel memory regions, where the channel uses all memory. Control and Feedback Channels are circular buffers whose size must be a power of two (2N). Prepending a header would prevent proper alignment which is why all communication channel metadata and synchronization objects are located in the Global Shared Memory region.\nSee Also: SharedChannel/ for more details about their implementation.\nTarget Process Mlos.Core Mlos.Core is a (C++) library used inside the target process. It provides an API to handle shared configs and exchange messages with Mlos.Agent via a shared channel.\nMlos.Core contains the following components:\n  MlosContext\nA class responsible for managing shared memory channels. It provides methods for sending telemetry and control messages to the Mlos.Agent as well as receiving feedback messages from it.\n  SharedConfigManager\nA class responsible for managing shared configs. It allows for registering configs in shared memory.\n  Shared Channel  Control Channel Feedback Channel  Mlos.Agent Mlos.NetCore Settings registry assemblies Grpc Server Experiment management Implementation details Shared Memory Channel\n"});index.add({'id':12,'href':'/MLOS/documentation/RepoOrganization/','title':"Repo Organization",'section':"Documentation",'content':"Repo Organization Some notes on the directory layout organization in this repo.\n There are build files (e.g. dirs.proj for msbuild or dotnet build, or Makefiles for make) in most directories to allow easy recursive building of that subtree you happen to be in.  Note: we provide Makefile wrappers in most directories to simply help invoke cmake and the Makefiles it generates\n  build/ contains configuration related to building MLOS components  For instance, .props and .targets files for definining and controlling common msbuild and dotnet build properites and targets are contained there, as are various style check configurations.   Note: For this reason, cmake output is redirected to build.cmake/ instead.\n  source/ contains a directory for each component of MLOS, including unit test source code.  i.e. running msbuild or make in the source/ directory will build (and generally analyze) all of the projects, but not execute their tests. source/Examples/ contains sample target codes to optimize with the other MLOS components and help describe the integration methods source/Mlos.Notebooks/StartHere.ipynb contains a sample Notebook with a basic MLOS optimization walkthrough   test/ contains a directory and project to invoke each of the unit tests.  i.e. running msbuild or make in the test/ directory will also run all of the tests.   scripts/ contains some helper scripts to initialize development environments, install tools, invoke build pipelines, etc.  Auto generated content:\n out/ contains most of the intermediate build output, especially for msbuild and dotnet build portions  out/dotnet contains the msbuild and dotnet build outputs (for Windows) out/Mlos.CodeGen.out contains code generation output from each SettingsRegistry project, organized by originating source/ project directory out/Grpc.out contains the output for the grpc messages between the Mlos.Agents   target/ contains final binaries and libraries produced by msbuild that are suitable for execution build.cmake/ contains most of the output from cmake  Note: this is by convention. Though we provide some configurations to help use this path, other tools or IDEs may override it.\n  tools/ is created for items the cake build scripts may fetch  "});index.add({'id':13,'href':'/MLOS/notebooks/OptimizerMonitor/','title':"Optimizer Monitor",'section':"Notebooks",'content':"Goal The goal of this notebook is to provide a UI to a data scientist or dev 2.0 to interact with the optimizers residing in the optimizer microservice.\nTODO   Integrate Model Tomograph:\n Change Predict() to return a pandas df: change change/eliminate the prediction class.   Fix the individual models input spaces so that they reject invalid points. Add color scale Add cross-hairs    Display current optimum:\n Add this functionality to the grpc implementation.    Display parameter importance\n  Display pareto frontier\n  Allow data scientist/dev2.0 to export all data ingested by the optimizer:\n Check in DataSet and DataSetView classes Integrate the DataSet and DataSetView classes into the framework    Display Optimizer/Model robustness statistics:\n Compute the model fit values: r**2, rmse, etc., during fit Expose them over grpc    Turn on logging to console in the service process.\n  from IPython.core.display import display, HTML display(HTML(\u0026#34;\u0026lt;style\u0026gt;.container { width:100% !important; }\u0026lt;/style\u0026gt;\u0026#34;)) import grpc from mlos.Grpc.OptimizerMonitor import OptimizerMonitor grpc_port = 50051 optimizer_service_grpc_channel = grpc.insecure_channel(f\u0026#39;localhost:{grpc_port}\u0026#39;) optimizer_monitor = OptimizerMonitor(grpc_channel=optimizer_service_grpc_channel) for optimizer in optimizer_monitor.get_existing_optimizers(): print(optimizer.id) optimizer = optimizer_monitor.get_optimizer_by_id(\u0026#34;0\u0026#34;) print(optimizer.suggest()) import os os.getpid() from mlos.Tomograph.ModelTomograph import ModelTomograph tomograph = ModelTomograph(optimizer=optimizer) tomograph.plot() "});index.add({'id':14,'href':'/MLOS/notebooks/SmartCache/','title':"Smart Cache",'section':"Notebooks",'content':"Goal The goal of this notebook is to optimize SmartCache.\nfrom IPython.core.display import display, HTML display(HTML(\u0026#34;\u0026lt;style\u0026gt;.container { width:100% !important; }\u0026lt;/style\u0026gt;\u0026#34;)) TODO Lots to do here.\nFor once - this is probably not the workflow we want. We likely want to:\n Start the Optimizer in a separate process so that we can monitor its progress. Maybe we should have a separate notebook just for Optimizer Monitoring. Start the Mlos.Agent + Workload in a separate process. Perhaps communicate with them over gRPC. This would bring us closer to the C# scenario but is not a top priority. We need to be able to see how well the cache is doing: what are its stats. We want to modify the workload so that one configuration dominates.  from concurrent.futures import ThreadPoolExecutor import os from subprocess import Popen, CREATE_NEW_CONSOLE import sys from threading import Thread import grpc import pandas as pd from mlos.Grpc.BayesianOptimizerFactory import BayesianOptimizerFactory from mlos.Grpc.BayesianOptimizerProxy import BayesianOptimizerProxy from mlos.Grpc.OptimizerMonitor import OptimizerMonitor from mlos.Logger import create_logger from mlos.Examples.SmartCache import SmartCacheWorkloadGenerator, SmartCache from mlos.Examples.SmartCache.TelemetryAggregators.WorkingSetSizeEstimator import WorkingSetSizeEstimator from mlos.Grpc.OptimizerMicroserviceServer import OptimizerMicroserviceServer from mlos.Mlos.Infrastructure import CommunicationChannel, SharedConfig from mlos.Mlos.SDK import mlos_globals, MlosGlobalContext, MlosExperiment, MlosAgent from mlos.Mlos.SDK.CommonAggregators.Timer import Timer from mlos.Optimizers.BayesianOptimizer import BayesianOptimizerConfig from mlos.Optimizers.OptimizationProblem import OptimizationProblem, Objective from mlos.Spaces import Point, SimpleHypergrid, ContinuousDimension import mlos.global_values as global_values grpc_port = 50051 mlos_python_path = os.path.abspath(os.path.join(os.getcwd(), \u0026#34;..\u0026#34;, \u0026#34;Mlos.Python\u0026#34;)) os.getpid() # Let\u0026#39;s stand up the Optimizer Service # python_path = sys.executable optimizer_microservice_launcher_path = os.path.abspath(os.path.join(mlos_python_path, \u0026#34;mlos\u0026#34;, \u0026#34;start_optimizer_microservice.py\u0026#34;)) command = f\u0026#34;{python_path} {optimizer_microservice_launcher_path} launch --port {grpc_port}\u0026#34; print(command) server_process = Popen(command, creationflags=CREATE_NEW_CONSOLE) logger = create_logger(\u0026#39;Optimizing Smart Cache\u0026#39;) optimizer_service_grpc_channel = grpc.insecure_channel(f\u0026#39;localhost:{grpc_port}\u0026#39;) bayesian_optimizer_factory = BayesianOptimizerFactory(grpc_channel=optimizer_service_grpc_channel, logger=logger) # Optimization Problem # optimization_problem = OptimizationProblem( parameter_space=SmartCache.parameter_search_space, objective_space=SimpleHypergrid(name=\u0026#34;objectives\u0026#34;, dimensions=[ContinuousDimension(name=\u0026#34;miss_rate\u0026#34;, min=0, max=1)]), context_space=None, # TODO add the working set size estimators. objectives=[Objective(name=\u0026#34;miss_rate\u0026#34;, minimize=True)] ) optimizer = bayesian_optimizer_factory.create_remote_optimizer( optimization_problem=optimization_problem, optimizer_config=BayesianOptimizerConfig.DEFAULT ) # Now onto the mlos global context - this is where the smart component can send its telemetry and check for new config. # Note that the communication channel and shared config are - well - shared between mlos agent and the smart component. # global_values.declare_singletons() communication_channel = CommunicationChannel() shared_config = SharedConfig() mlos_globals.init_mlos_global_context() mlos_globals.mlos_global_context = MlosGlobalContext(communication_channel=communication_channel, shared_config=shared_config) # Now let\u0026#39;s create the MlosAgent. Note that this architecture mirrors our native architecture, except it\u0026#39;s much less performant. # mlos_agent = MlosAgent( logger=logger, communication_channel=communication_channel, shared_config=shared_config, mlos_service_endpoint=None, # TODO: remove this completely from everywhere. bayesian_optimizer_grpc_channel=optimizer_service_grpc_channel ) mlos_agent_thread = Thread(target=mlos_agent.run) mlos_agent_thread.start() # Let\u0026#39;s register SmartCache as a legal smart component. # mlos_agent.add_allowed_component_type(SmartCache) mlos_agent.add_allowed_component_type(SmartCacheWorkloadGenerator) # TODO: for the very first exercise we should have a fixed workload. smart_cache_workload = SmartCacheWorkloadGenerator(logger=logger) # Here we define the telemetry aggregators used in the experiments. # working_set_size_estimator = WorkingSetSizeEstimator() # TODO: this should be yet another telemetry aggregator, not a standalone function. # def set_new_cache_configuration(elapsed_time_ms): # TODO: remove the globals. global logger global working_set_size_estimator global optimizer global mlos_agent # Just to make sure the optimizer monitor and the tomograph are working: let\u0026#39;s register some dummy results. # TODO: aggregate telemetry to determine the true miss rate for this cache for a given config. # existing_config = mlos_agent.get_configuration(component_type=SmartCache) if existing_config is not None: features_df = existing_config.to_pandas() if existing_config.implementation == \u0026#34;MRU\u0026#34;: miss_rate = -1000 + existing_config.mru_cache_config.cache_size else: miss_rate = 1000 + existing_config.lru_cache_config.cache_size objectives_df = pd.DataFrame({\u0026#39;miss_rate\u0026#39;: [miss_rate]}) optimizer.register(features_df, objectives_df) # TODO: have the working set size estimate be part of the context passed to the optimizer. # current_estimate = working_set_size_estimator.estimate_working_set_size() logger.info(f\u0026#34;Estimated working set size: {current_estimate.chapman_estimator}\u0026#34;) new_config_values = optimizer.suggest() mlos_agent.set_configuration( component_type=SmartCache, new_config_values=new_config_values ) # TODO: we need aggregators to spit out hit rate, as well as other Cache Info (cache entry staleness, cache saturation, etc.) cache_config_timer = Timer( timeout_ms=200, observer_callback=set_new_cache_configuration ) # Now finally we build the experiment. # smart_cache_experiment = MlosExperiment( smart_component_types=[SmartCache], telemetry_aggregators=[cache_config_timer, working_set_size_estimator] ) # We have the experiment, let\u0026#39;s start it. # smart_cache_workload_thread = Thread(target=smart_cache_workload.run, args=(150,)) smart_cache_workload_thread.start() mlos_agent.start_experiment(smart_cache_experiment) smart_cache_workload_thread.join() mlos_agent.stop_experiment(smart_cache_experiment) mlos_globals.mlos_global_context.stop_clock() # Clean up # mlos_globals.mlos_global_context.stop_clock() mlos_agent.stop_all() # Kill the server. # server_process.kill() "});index.add({'id':15,'href':'/MLOS/notebooks/StartHere/','title':"Start Here",'section':"Notebooks",'content':"Objective The goal of this notebook is to guide you through the process of executing an optimization process in Mlos.\nSteps  Select build configuration. Generate the secrets file. Build the docker image. Launch the docker container. Launch Mlos.Agent. Launch SmartCache.exe benchmark.  Prerequisites  Build the Mlos project. The build configuration (Debug vs. Retail) must match your choice below. Have Docker installed and available. This notebook is run with {MLOS_ROOT}\\source\\Mlos.Notebooks as a working directory (default if you open from ADS or VS Code).  import json import os import subprocess import time from utils import generate_random_password, build_docker_image, run_docker_container, stop_docker_container, remove_docker_container mlos_root_directory = os.path.abspath(os.path.join(os.getcwd(), \u0026#34;../..\u0026#34;)) Select build configuration ATTENTION: Optimization of DEBUG builds is pointless. Select DEBUG only if you are trying to debug these projects.\nbuild_configuration = \u0026#39;Release\u0026#39; # you can change it to \u0026#39;Debug\u0026#39; here. assert build_configuration in (\u0026#39;Release\u0026#39;, \u0026#39;Debug\u0026#39;) if build_configuration == \u0026#39;Release\u0026#39;: obj_dir = \u0026#34;obj\u0026#34; else: obj_dir = \u0026#34;objd\u0026#34; mlos_agent_server_exe_path = os.path.abspath(os.path.join(mlos_root_directory, \u0026#34;out/dotnet/source/Mlos.Agent.Server\u0026#34;, obj_dir, \u0026#34;AnyCPU\u0026#34;, \u0026#34;Mlos.Agent.Server.exe\u0026#34;)) smart_cache_exe_path = os.path.abspath(os.path.join(mlos_root_directory, \u0026#34;out/dotnet/source/Examples/SmartCache\u0026#34;, obj_dir, \u0026#34;x64\u0026#34;, \u0026#34;SmartCache.exe\u0026#34;)) if not (os.path.exists(mlos_agent_server_exe_path) and os.path.exists(smart_cache_exe_path)): print(f\u0026#34;Are you sure you have done a build in a {build_configuration} configuration?\u0026#34;) Generate the secrets file  Note: We are moving away from using SqlRPC and towards gRPC for communication between Mlos.Agent and the Optimizer Service. However, until that migration is complete, Mlos.Agent has to know how to connect to Sql Server.\n The secrets file is a simple json file generated by the code cell below.\noverwrite_secrets = False secrets_file_path = os.path.abspath(os.path.join(mlos_root_directory, \u0026#34;source/Mlos.Python/Secrets/local_docker_connection_string.json\u0026#34;)) if os.path.exists(secrets_file_path) and not overwrite_secrets: # Secrets already exist. We need to grab the password for later use. # print(f\u0026#34;Secrets file {secrets_file_path} already exists.\u0026#34;) with open(secrets_file_path, \u0026#39;r\u0026#39;) as in_file: secrets = json.load(in_file) sa_password = secrets[\u0026#39;Password\u0026#39;] else: # We need to create the secrets file from the template. sa_password = generate_random_password() sample_secrets_file_path = os.path.abspath(os.path.join(mlos_root_directory, \u0026#34;source/Mlos.Python/Secrets/sample_docker_connection_string.json\u0026#34;)) with open(sample_secrets_file_path, \u0026#39;r\u0026#39;) as in_file: secrets_dict = json.load(in_file) secrets_dict[\u0026#39;Password\u0026#39;] = sa_password with open(secrets_file_path, \u0026#39;w\u0026#39;) as out_file: json.dump(secrets_dict, out_file, indent=2) print(f\u0026#34;Wrote a new secrets file to {secrets_file_path}.\u0026#34;) Secrets file c:\\Users\\bpkroth\\src\\MLOS\\MLOS.msdata.2\\source\\Mlos.Python\\Secrets\\local_docker_connection_string.json already exists.  Build Docker image The optimizer lives inside the Docker. Let\u0026rsquo;s build the image.\nbuild_docker_image(sa_password) Step 1/15 : FROM microsoft/mssql-server-linux:latest ---\u0026gt; 314918ddaedf Step 2/15 : RUN apt-get -y update \u0026amp;\u0026amp; apt-get install -y software-properties-common \u0026amp;\u0026amp; add-apt-repository -y ppa:deadsnakes/ppa \u0026amp;\u0026amp; apt-get -y update \u0026amp;\u0026amp; apt-get install -y python3.7 python3-pip \u0026amp;\u0026amp; apt-get install -y build-essential libssl-dev libffi-dev python3-dev python3.7-dev unixodbc-dev \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* ---\u0026gt; Using cache ---\u0026gt; c96a7f675e7e Step 3/15 : RUN python3.7 -m pip install pip ---\u0026gt; Using cache ---\u0026gt; feb04a146619 Step 4/15 : RUN python3.7 -m pip install --upgrade pip ---\u0026gt; Using cache ---\u0026gt; 199aa4fecd21 Step 5/15 : RUN mkdir -p /usr/src/Mlos.Python ---\u0026gt; Using cache ---\u0026gt; 75325321633c Step 6/15 : WORKDIR /usr/src/ ---\u0026gt; Using cache ---\u0026gt; c28de51505c5 Step 7/15 : COPY ./requirements.txt ./Mlos.Python/requirements.txt ---\u0026gt; Using cache ---\u0026gt; 9e4576c57340 Step 8/15 : RUN python3.7 -m pip install -r /usr/src/Mlos.Python/requirements.txt ---\u0026gt; Using cache ---\u0026gt; dd3f294d79e3 Step 9/15 : COPY . ./Mlos.Python ---\u0026gt; Using cache ---\u0026gt; 33fb9dad43b5 Step 10/15 : ENV ACCEPT_EULA=Y ---\u0026gt; Using cache ---\u0026gt; 4f19a90fbef2 Step 11/15 : ARG SA_PASSWORD=DEFAULT_SA_PASSWORD ---\u0026gt; Using cache ---\u0026gt; 154868f57d1a Step 12/15 : RUN (/opt/mssql/bin/sqlservr --accept-eula \u0026amp; ) | grep -q \u0026quot;Service Broker manager has started\u0026quot; \u0026amp;\u0026amp; /opt/mssql-tools/bin/sqlcmd -S127.0.0.1 -Usa -P${SA_PASSWORD} -i ./Mlos.Python/MlosOptimizationServices/ModelsDatabase/SQLScripts/Schema.sql ---\u0026gt; Using cache ---\u0026gt; 48d1a8c19169 Step 13/15 : EXPOSE 1433 ---\u0026gt; Using cache ---\u0026gt; 63fd96771c97 Step 14/15 : ENV SA_PASSWORD=$SA_PASSWORD ---\u0026gt; Using cache ---\u0026gt; 94ec12721485 Step 15/15 : CMD /opt/mssql/bin/sqlservr \u0026amp; cd Mlos.Python; python3.7 start_mlos_optimization_runtime.py launch --database-connection-string-file ./Secrets/local_docker_connection_string.json ---\u0026gt; Using cache ---\u0026gt; 47630835a8d0 Successfully built 47630835a8d0 Successfully tagged mssql-server-linux-with-mlos-python:latest SECURITY WARNING: You are building a Docker image from Windows against a non-Windows Docker host. All files and directories added to build context will have '-rwxr-xr-x' permissions. It is recommended to double check and reset permissions for sensitive files and directories.  Run Docker container run_docker_container() docker run --detach -p1433:1433 --name MlosOptimizerService mssql-server-linux-with-mlos-python bb2ea175d37a4428e885e17bae73e90c784514b779aad27fc0a4b850ea1a3f47  Launch Mlos.Agent.Server We need to launch Mlos.Agent.Server and let it communicate with the Optimizer.\nprint(mlos_agent_server_exe_path, f\u0026#39;\u0026#34;{secrets_file_path}\u0026#34;\u0026#39;) mlos_agent_server_process = subprocess.Popen([mlos_agent_server_exe_path, secrets_file_path], creationflags=subprocess.CREATE_NEW_CONSOLE) time.sleep(15) # TODO: wait for Mlos.Agent.Server to signal readiness instead of blindly waiting. c:\\Users\\bpkroth\\src\\MLOS\\MLOS.msdata.2\\out\\dotnet\\source\\Mlos.Agent.Server\\obj\\AnyCPU\\Mlos.Agent.Server.exe \u0026quot;c:\\Users\\bpkroth\\src\\MLOS\\MLOS.msdata.2\\source\\Mlos.Python\\Secrets\\local_docker_connection_string.json\u0026quot;  Launch SmartCache microbenchmark print(smart_cache_exe_path) smart_cache_process = subprocess.Popen([smart_cache_exe_path], creationflags=subprocess.CREATE_NEW_CONSOLE) # wait for the process to exit # while smart_cache_process.poll() is None: time.sleep(1) print(\u0026#34;SmartCache.exe exited.\u0026#34;) c:\\Users\\bpkroth\\src\\MLOS\\MLOS.msdata.2\\out\\dotnet\\source\\Examples\\SmartCache\\obj\\x64\\SmartCache.exe SmartCache.exe exited.  Clean up Docker stop_docker_container() remove_docker_container() docker stop MlosOptimizerService MlosOptimizerService docker container rm MlosOptimizerService MlosOptimizerService  "});index.add({'id':16,'href':'/MLOS/README/','title':"R E a D M E",'section':"",'content':"MLOS: Machine Learning Optimized Systems MLOS: An Infrastructure for Automated Software Performance Engineering  MLOS is an ML-powered infrastructure and methodology to democratize and automate Performance Engineering. MLOS enables continuous, instance-based, robust, and trackable systems optimization.\n From the MLOS paper at DEEM 2020\nOverview Problem All systems software (e.g. SqlServer, MySQL, LevelDB, OpenSSL, etc.) is full of parameter choices.\nSometimes these are encoded in the software as constants embedded in the code (e.g. choice of abstract data structure implementation, buffer limit size or alignment, etc.). Other times they may be exposed as configuration parameters either at startup or runtime.\nCareful selection of these parameters can yield dramatic performance differences for different contexts of a system (e.g. different workloads, hardware, etc.). Note that performance can be interpreted in different ways (e.g. reducing average/variability of latency/memory, increasing throughput, decreasing MTTR, etc.)\nGenerally speaking, this process is referred to as Software Performance Engineering, and typically involves a lot of manual effort that is brittle and not well tracked.\nGoals MLOS is about using machine-learning and data-science to optimize systems for a given context through these tunable choices.\nRoughly, this can happen in two modes:\n  Offline (e.g. at development time)\nIn this case, developers can use (micro)benchmarks to explore a parameter space for a component either interactively or with a background CI/CD pipeline and then interact with that data through a notebook experience to select the right value to check in to the code, along with the results of the experiments and analysis, all encoded in the notebook.\n  Online (e.g. at runtime)\nIn this case a system component provides hooks to adjust its parameters at runtime and exports data about its current state/performance. These can be combined with additional contextual information from the system to build a model (or simple heuristics) to invoke the hooks to adjust the component to improve performance at runtime.\n  Architecture To achieve this MLOS provides:\n  Code Annotations to help describe additional settings metadata for tunables (a.k.a. Settings).\nFor instance, metadata can include things like constraints on acceptable values a Setting can take on as well as developer intuition to help guide the automated search process.\nCurrently these are implemented as C# Attributes to provide reflection and easy cross-platform and cross-compiler support for C++ projects.\n  Code Generation tools to use that metadata to expose those settings to different target systems/languages (e.g. Python Notebooks, C++, C#, etc.)\nFor instance, we generate efficient messages over shared memory communication channels for\n  exporting data about the component using that Setting\nFor instance, this may include performance statistics, workload traces, etc.\n  receiving feedback (e.g. to change the Setting\u0026rsquo;s value)\nThis may involve a reconfiguration step or simply update a cache for the next instantiation to read.\n    An external agent (Mlos.Agent.Server) which can consume the information exported by the target system (e.g. SqlServer, MySQL, LevelDB, etc.) with mimimal impact on the target system.\nThe external agent can perform workload summarization, binning, cataloging, model inference, heuristic invocation, etc. based on the events exposed by the target system to then influence it.\nOnce hooks are created in the target system, iteration on the external agent can be more rapidly developed and deployed.\n  Python only installation Some of the examples require only the installation of the mlos Python library. These examples do not use the shared memory infrastructure. To use this simplified installation, it\u0026rsquo;s recommended to use the Anaconda python distribution and create a new conda environment:\n$ conda create -n mlos_environment $ conda activate mlos_environment You can download the mlos code using git:\n$ git clone git@github.com:microsoft/MLOS.git To install the Python library, change to the Python directory and install with pip:\n$ cd MLOS/source/Mlos.Python $ pip install -e . You can also install the package directly without checking out the code:\n$ pip install \u0026quot;git+https://github.com/microsoft/MLOS.git#egg=mlos\u0026amp;subdirectory=source/Mlos.Python\u0026quot; However, this does not include the examples.\nAfter this installation, you can run any of the Python-only example notebooks. A good place to start is the introduction to Bayesian Optimization.\nFull Build (C# and C++ components) MLOS supports Windows and Linux build environments.\nFor detailed instructions, please refer to:\n Prerequisites Build  Examples Code and documentation for examples of using MLOS to optimize a system are described in the Notebooks section. Additional code is in the source/Examples source directory. You can find the source of the notebooks on github as well.\nDocumentation   Additional overview documentation is available in the documentation tree.\n  Individual components may also include more detailed documentation in their respective subdirectories.\n  Contributing We welcome contributions! Please see Contributing and Code of Conduct for details.\nAlso, please see the Roadmap of planned features.\nContact For more formal enquiries, you can contact us.\nLicense  MIT License  "});})();